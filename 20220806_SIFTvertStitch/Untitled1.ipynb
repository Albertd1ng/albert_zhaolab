{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af7b6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3353 3825]\n"
     ]
    }
   ],
   "source": [
    "img_path=r'F:'\n",
    "file_name=r'Project%d'\n",
    "img_name=r'Region 1_Merged'\n",
    "img_save_path=r'F:\\Project_All'\n",
    "save_img_name=r'Region 1_Merged%.4d'\n",
    "save_path=r'C:\\Users\\dingj\\ZhaoLab\\20220806_SIFTvertStitch'\n",
    "stitch_layer_num=3\n",
    "\n",
    "dim_elem_num,dim_len,voxel_len=get_img_info(save_path)\n",
    "axis_range_array=np.zeros((stitch_layer_num,6))\n",
    "for i in range(1,stitch_layer_num+1):\n",
    "    axis_range_array[i-1,:]=np.load(save_path+r'\\axis_range_stitch_%.4d.npy'%(i)).reshape((1,-1))\n",
    "xy_axis_range=np.zeros((2,2))\n",
    "xy_axis_range[0,0],xy_axis_range[0,1]=np.min(axis_range_array[:,0])-voxel_len[0]*2,np.max(axis_range_array[:,1])+voxel_len[0]*100\n",
    "xy_axis_range[1,0],xy_axis_range[1,1]=np.min(axis_range_array[:,2])-voxel_len[0]*2,np.max(axis_range_array[:,3])+voxel_len[0]*100\n",
    "xy_voxel_num=np.int64(np.round((xy_axis_range[:,1]-xy_axis_range[:,0])/voxel_len[0:2])+1)\n",
    "print(xy_voxel_num)\n",
    "\n",
    "img_num=0\n",
    "for i in range(stitch_layer_num):\n",
    "    first_last_index=np.load(save_path+r'\\first_last_index_stitch_%.4d.npy'%(i+1))\n",
    "    axis_range=np.load(save_path+r'\\axis_range_stitch_%.4d.npy'%(i+1))\n",
    "    this_img_path=img_path+'\\\\'+file_name%(i+1)\n",
    "    x_th=np.int64(np.round((axis_range[0,0]-xy_axis_range[0,0])/voxel_len[0]))\n",
    "    y_th=np.int64(np.round((axis_range[1,0]-xy_axis_range[1,0])/voxel_len[1]))\n",
    "    for j in range(first_last_index[0],first_last_index[1]):\n",
    "        this_img=np.zeros((xy_voxel_num[1::-1]),dtype='uint8')\n",
    "        img_2D=import_2D_img(this_img_path,img_name,j)\n",
    "        if i==0:\n",
    "            m1=np.mean(img_2D)\n",
    "        if i==1:\n",
    "            m2=np.mean(img_2D)\n",
    "            img_2D=img_2D.astype('float32')\n",
    "            img_2D=np.uint8(np.clip(m1/m2*img_2D,0,255))\n",
    "        img_2D=np.uint8(0.8*img_2D.astype('float32'))\n",
    "        this_img[y_th:y_th+img_2D.shape[0],x_th:x_th+img_2D.shape[1]]=img_2D\n",
    "        cv2.imwrite(r'%s\\Region 1_Merged%.4d.tif'%(img_save_path,img_num),this_img)\n",
    "        img_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e3666f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.88793758e-06, 2.88804799e-06, 4.91644000e-06])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxel_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1109057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function clip in module numpy:\n",
      "\n",
      "clip(a, a_min, a_max, out=None, **kwargs)\n",
      "    Clip (limit) the values in an array.\n",
      "    \n",
      "    Given an interval, values outside the interval are clipped to\n",
      "    the interval edges.  For example, if an interval of ``[0, 1]``\n",
      "    is specified, values smaller than 0 become 0, and values larger\n",
      "    than 1 become 1.\n",
      "    \n",
      "    Equivalent to but faster than ``np.minimum(a_max, np.maximum(a, a_min))``.\n",
      "    \n",
      "    No check is performed to ensure ``a_min < a_max``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing elements to clip.\n",
      "    a_min, a_max : array_like or None\n",
      "        Minimum and maximum value. If ``None``, clipping is not performed on\n",
      "        the corresponding edge. Only one of `a_min` and `a_max` may be\n",
      "        ``None``. Both are broadcast against `a`.\n",
      "    out : ndarray, optional\n",
      "        The results will be placed in this array. It may be the input\n",
      "        array for in-place clipping.  `out` must be of the right shape\n",
      "        to hold the output.  Its type is preserved.\n",
      "    **kwargs\n",
      "        For other keyword-only arguments, see the\n",
      "        :ref:`ufunc docs <ufuncs.kwargs>`.\n",
      "    \n",
      "        .. versionadded:: 1.17.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    clipped_array : ndarray\n",
      "        An array with the elements of `a`, but where values\n",
      "        < `a_min` are replaced with `a_min`, and those > `a_max`\n",
      "        with `a_max`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    :ref:`ufuncs-output-type`\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    When `a_min` is greater than `a_max`, `clip` returns an \n",
      "    array in which all values are equal to `a_max`, \n",
      "    as shown in the second example.  \n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(10)\n",
      "    >>> a\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "    >>> np.clip(a, 1, 8)\n",
      "    array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])\n",
      "    >>> np.clip(a, 8, 1)\n",
      "    array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "    >>> np.clip(a, 3, 6, out=a)\n",
      "    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])\n",
      "    >>> a\n",
      "    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])\n",
      "    >>> a = np.arange(10)\n",
      "    >>> a\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "    >>> np.clip(a, [3, 4, 1, 1, 1, 4, 4, 4, 4, 4], 8)\n",
      "    array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0039992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "def get_img_info(save_path):\n",
    "    dim_elem_num=np.load(save_path+r'\\dim_elem_num.npy')\n",
    "    dim_len=np.load(save_path+r'\\dim_len.npy')\n",
    "    voxel_len=np.load(save_path+r'\\voxel_len.npy')\n",
    "    return dim_elem_num,dim_len,voxel_len\n",
    "\n",
    "def import_2D_img(img_path,img_name,z_th):\n",
    "    one_img_name=r'%s\\%s_z%.2d_RAW_ch00.tif'%(img_path,img_name,z_th)\n",
    "    return cv2.imread(one_img_name,cv2.IMREAD_GRAYSCALE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
